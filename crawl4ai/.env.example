# =============================================================================
# Crawl4ai Configuration
# AI-powered web crawler with Ollama integration
# =============================================================================

# -----------------------------------------------------------------------------
# Ollama LLM Integration (REQUIRED - Pre-configured for local setup)
# -----------------------------------------------------------------------------
# Connects to Ollama running on macOS host for GPU acceleration
LLM_PROVIDER=ollama/gpt-oss
OLLAMA_API_BASE=http://host.docker.internal:11434
OLLAMA_PROXY_API_BASE=http://host.docker.internal:11434
OLLAMA_API_KEY=no-token

# Dummy OpenAI key (required but not used with Ollama)
OPENAI_API_KEY=dummy

# -----------------------------------------------------------------------------
# Proxy Configuration (OPTIONAL)
# -----------------------------------------------------------------------------
# Uncomment to use a proxy for web crawling
# Useful for bypassing rate limits or accessing geo-restricted content
# HTTP_PROXY=http://proxy-server:port
# HTTPS_PROXY=https://proxy-server:port
# SOCKS_PROXY=socks5://proxy-server:port

# Example with authentication:
# HTTP_PROXY=http://username:password@proxy-server:port

# -----------------------------------------------------------------------------
# Service Information
# -----------------------------------------------------------------------------
# Access URL: http://crawl4ai.localhost
#
# Features:
# - AI-powered web content extraction using local Ollama models
# - Headless browser support (Xvfb virtual display)
# - JavaScript rendering capabilities
# - LLM-based content understanding and summarization
#
# Technical:
# - Runs with Xvfb for headless browser operation
# - Uses 1GB shared memory for browser rendering
# - Data stored in ./data directory
